{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee5321d-d279-4bc6-8285-57a5d4a58ef1",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201fb057-6645-4047-99a3-42756338b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TFBertLMHeadModel\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from gptq import GPTQConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98574cec-80d7-4259-b2d9-e6d70cec9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
    "    model, optimizer, training_dataloader, scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60530a72-4070-4ed2-a5a7-6627d9a9fd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 SUPER'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630eb89f-e4eb-4740-ac1a-ed60468431b0",
   "metadata": {},
   "source": [
    "\n",
    "#### If you want to download a model or a tokenizer from Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c69536bf-3741-4516-b1a5-5ca35368de11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b45373ee124be4b969e1249794a49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging into HuggingFace account\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "# my_token:  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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa4840-bca9-43b3-8ed6-a2b47ed3c7a7",
   "metadata": {},
   "source": [
    "## Model and Tokenizer declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeca32d8-7660-4922-9f88-8ef123c60448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"bert-base-uncased\"\n",
    "# model_name = \"EleutherAI/pythia-70m\"\n",
    "model_name = 'meta-llama/Llama-2-7b-chat-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04aa7483-0537-497f-893a-67845e65586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gptq_config = GPTQConfig(bits=4, dataset = \"c4\", tokenizer=tokenizer)\n",
    "# quantization = GPTQConfig(bits=4, dataset = dataset, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a41e1ac9-93fa-4138-a79f-687f98158b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b947c47a94534814a8e68506e04861e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 8.00 GiB total capacity; 6.00 GiB already allocated; 942.67 MiB free; 6.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_empty_weights\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m init_empty_weights():\n\u001b[1;32m----> 5\u001b[0m     my_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:2903\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2894\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   2896\u001b[0m     (\n\u001b[0;32m   2897\u001b[0m         model,\n\u001b[0;32m   2898\u001b[0m         missing_keys,\n\u001b[0;32m   2899\u001b[0m         unexpected_keys,\n\u001b[0;32m   2900\u001b[0m         mismatched_keys,\n\u001b[0;32m   2901\u001b[0m         offload_index,\n\u001b[0;32m   2902\u001b[0m         error_msgs,\n\u001b[1;32m-> 2903\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2921\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   2922\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3260\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3250\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[0;32m   3251\u001b[0m     state_dict,\n\u001b[0;32m   3252\u001b[0m     model_state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3256\u001b[0m     ignore_mismatched_sizes,\n\u001b[0;32m   3257\u001b[0m )\n\u001b[0;32m   3259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[1;32m-> 3260\u001b[0m     new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3267\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3268\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3276\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[0;32m   3277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:717\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[1;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m    714\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate`\u001b[39;00m\n\u001b[1;32m--> 717\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;129;01mand\u001b[39;00m param_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:313\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[1;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[0;32m    311\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 313\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 8.00 GiB total capacity; 6.00 GiB already allocated; 942.67 MiB free; 6.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "from accelerate import init_empty_weights\n",
    "\n",
    "with init_empty_weights():\n",
    "    my_model = AutoModelForCausalLM.from_pretrained(model_name\n",
    "                                             ,device_map=\"auto\" \n",
    "                                             ,torch_dtype=torch.float16\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49059e2b-c455-4bfa-88f2-c265ee94c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 2\n",
    "\n",
    "from accelerate import load_checkpoint_and_dispatch\n",
    "\n",
    "model = load_checkpoint_and_dispatch(\n",
    "    model, checkpoint=checkpoint_file, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8cf1a35-88ea-487c-b96e-d4916deb0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "from accelerate import infer_auto_device_map, init_empty_weights\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "device_map = infer_auto_device_map(model, dtype=\"float16\")\n",
    "# device_map = infer_auto_device_map(model, no_split_module_classes=[\"OPTDecoderLayer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a954941f-d180-4a29-b267-60aa9b6d633f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens': 0,\n",
       " 'model.layers.0': 0,\n",
       " 'model.layers.1': 0,\n",
       " 'model.layers.2': 0,\n",
       " 'model.layers.3': 0,\n",
       " 'model.layers.4': 0,\n",
       " 'model.layers.5': 0,\n",
       " 'model.layers.6': 0,\n",
       " 'model.layers.7.self_attn.q_proj': 0,\n",
       " 'model.layers.7.self_attn.k_proj': 0,\n",
       " 'model.layers.7.self_attn.v_proj': 0,\n",
       " 'model.layers.7.self_attn.o_proj': 'cpu',\n",
       " 'model.layers.7.self_attn.rotary_emb': 'cpu',\n",
       " 'model.layers.7.mlp': 'cpu',\n",
       " 'model.layers.7.input_layernorm': 'cpu',\n",
       " 'model.layers.7.post_attention_layernorm': 'cpu',\n",
       " 'model.layers.8': 'cpu',\n",
       " 'model.layers.9': 'cpu',\n",
       " 'model.layers.10': 'cpu',\n",
       " 'model.layers.11': 'cpu',\n",
       " 'model.layers.12': 'cpu',\n",
       " 'model.layers.13': 'cpu',\n",
       " 'model.layers.14': 'cpu',\n",
       " 'model.layers.15.self_attn.q_proj': 'cpu',\n",
       " 'model.layers.15.self_attn.k_proj': 'cpu',\n",
       " 'model.layers.15.self_attn.v_proj': 'cpu',\n",
       " 'model.layers.15.self_attn.o_proj': 'disk',\n",
       " 'model.layers.15.self_attn.rotary_emb': 'disk',\n",
       " 'model.layers.15.mlp': 'disk',\n",
       " 'model.layers.15.input_layernorm': 'disk',\n",
       " 'model.layers.15.post_attention_layernorm': 'disk',\n",
       " 'model.layers.16': 'disk',\n",
       " 'model.layers.17': 'disk',\n",
       " 'model.layers.18': 'disk',\n",
       " 'model.layers.19': 'disk',\n",
       " 'model.layers.20': 'disk',\n",
       " 'model.layers.21': 'disk',\n",
       " 'model.layers.22': 'disk',\n",
       " 'model.layers.23': 'disk',\n",
       " 'model.layers.24': 'disk',\n",
       " 'model.layers.25': 'disk',\n",
       " 'model.layers.26': 'disk',\n",
       " 'model.layers.27': 'disk',\n",
       " 'model.layers.28': 'disk',\n",
       " 'model.layers.29': 'disk',\n",
       " 'model.layers.30': 'disk',\n",
       " 'model.layers.31': 'disk',\n",
       " 'model.norm': 'disk',\n",
       " 'lm_head': 'disk'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b0004e-0d84-44bb-8057-fb6aa38f96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "function 'cadam32bit_grad_fp32' not found\n",
      "CUDA SETUP: Loading binary D:\\NLP 1\\venv\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP 1\\venv\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model = TFBertLMHeadModel.from_pretrained(model_name)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;66;43;03m# ,torch_dtype=torch.float16\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43m,\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# base_model = AutoModelForCausalLM.from_pretrained(model_name)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m )\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3123\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3119\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3120\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[0;32m   3121\u001b[0m         }\n\u001b[0;32m   3122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m-> 3123\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3124\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[0;32m   3126\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[0;32m   3128\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[0;32m   3129\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[0;32m   3131\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[0;32m   3132\u001b[0m             )\n\u001b[0;32m   3133\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[0;32m   3135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "
     ]
    }
   ],
   "source": [
    "# model = TFBertLMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name\n",
    "                                             ,device_map=\"auto\" \n",
    "                                             # ,torch_dtype=torch.float16\n",
    "                                             ,load_in_8bit=True\n",
    "                                            )\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafa1638-e7d8-4713-8040-e26c7dc5f5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 13 15:22:47 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   53C    P2              36W / 215W |   7442MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2044    C+G   ...on\\116.0.1938.76\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      2304    C+G   ...0_x64__8wekyb3d8bbwe\\HxAccounts.exe    N/A      |\n",
      "|    0   N/A  N/A      2688    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6068    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A      6084    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      6828    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      7608    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8664    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9704    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     10016    C+G   ...on\\116.0.1938.76\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12252    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12588      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     13524    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14316    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     14356    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A     14448    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1afc7f8-29c2-48ea-b768-4a7348a4f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.modeling_llama.LlamaForCausalLM"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb94bb0-70ee-44dc-bfc1-74f826973c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c73bf69-160f-49d3-b1f9-192a2d45a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token    # for Eleuther model use this\n",
    "# tokenizer.pad_token = tokenizer.cls_token    # for Bert model use this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b6393-34e0-48fe-b75d-5f073650d8d0",
   "metadata": {},
   "source": [
    "## Preparing the dataset for Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397490d-7d4d-42a5-a82c-6cd72e614405",
   "metadata": {},
   "source": [
    "Provide a Json Lines (Jsonl) file containing question and answer pairs; like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b931e06-93db-4b56-ba16-2c7856d2fd72",
   "metadata": {},
   "source": [
    "{\"question\": \"what could be a use case of LLM for a hospital\", \"answer\": \"LLMs can have several applications in a hospital such as Assisstant for nurses\"}\n",
    "\n",
    "{\"question\": \"How AI is being used in medical industries?\", \"answer\":\" AI is being used in medical industries for various purposes such as disease diagnose\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd5967a-d5e8-4f06-b69c-85ef6d30a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"ds.jsonl\"\n",
    "dataset_path = \"ds-sat.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a9d54fa-8ad0-4f34-a322-ae4341354eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_df = pd.read_json(\"ds.jsonl\", lines=True)\n",
    "# dict_dataset = df.to_dict()\n",
    "# print(\"dataset contains \" + str(len(dict_dataset['question'])) + \" Q & A\")\n",
    "# dict_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ea013b-5432-4d82-a946-5d8e7741e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding and truncating mey be used if model input exceeds max_length\n",
    "max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2f1e52-849b-4c30-9ac4-5cf2f9b07f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(dict_dataset):\n",
    "    if \"question\" in dict_dataset and \"answer\" in dict_dataset:\n",
    "      text = dict_dataset[\"question\"][0] + dict_dataset[\"answer\"][0]\n",
    "    elif \"input\" in dict_dataset and \"output\" in dict_dataset:\n",
    "      text = dict_dataset[\"input\"][0] + dict_dataset[\"output\"][0]\n",
    "    else:\n",
    "      text = dict_dataset[\"text\"][0]\n",
    "\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d95024f-6c1b-4001-b663-65b15df691f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=dataset_path, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55bf2fb1-0669-414e-97d7-d4daaa48ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 45\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff6950b1-f8dc-436a-b601-12867dbfb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d55b67-4eaf-4872-87d2-b155150b235e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Why is satellite imagery a valuable source of data for assessing maritime traffic??',\n",
       " 'answer': 'Satellite imagery is a valuable source of data for assessing maritime traffic because it allows access to information that is difficult to obtain by other means. Satellites provide a global geographic coverage and collect information periodically with high temporal resolution. This means that satellite images can provide a comprehensive view of maritime traffic in a given region over time.',\n",
       " 'input_ids': [1,\n",
       "  3750,\n",
       "  338,\n",
       "  28421,\n",
       "  6382,\n",
       "  708,\n",
       "  263,\n",
       "  21114,\n",
       "  2752,\n",
       "  310,\n",
       "  848,\n",
       "  363,\n",
       "  24809,\n",
       "  292,\n",
       "  1766,\n",
       "  21998,\n",
       "  12469,\n",
       "  8773,\n",
       "  29903,\n",
       "  271,\n",
       "  20911,\n",
       "  6382,\n",
       "  708,\n",
       "  338,\n",
       "  263,\n",
       "  21114,\n",
       "  2752,\n",
       "  310,\n",
       "  848,\n",
       "  363,\n",
       "  24809,\n",
       "  292,\n",
       "  1766,\n",
       "  21998,\n",
       "  12469,\n",
       "  1363,\n",
       "  372,\n",
       "  6511,\n",
       "  2130,\n",
       "  304,\n",
       "  2472,\n",
       "  393,\n",
       "  338,\n",
       "  5189,\n",
       "  304,\n",
       "  4017,\n",
       "  491,\n",
       "  916,\n",
       "  2794,\n",
       "  29889,\n",
       "  12178,\n",
       "  514,\n",
       "  3246,\n",
       "  3867,\n",
       "  263,\n",
       "  5534,\n",
       "  1737,\n",
       "  12122,\n",
       "  23746,\n",
       "  322,\n",
       "  6314,\n",
       "  2472,\n",
       "  3785,\n",
       "  1711,\n",
       "  411,\n",
       "  1880,\n",
       "  25406,\n",
       "  10104,\n",
       "  29889,\n",
       "  910,\n",
       "  2794,\n",
       "  393,\n",
       "  28421,\n",
       "  4558,\n",
       "  508,\n",
       "  3867,\n",
       "  263,\n",
       "  15171,\n",
       "  6270,\n",
       "  1776,\n",
       "  310,\n",
       "  1766,\n",
       "  21998,\n",
       "  12469,\n",
       "  297,\n",
       "  263,\n",
       "  2183,\n",
       "  5120,\n",
       "  975,\n",
       "  931,\n",
       "  29889],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [1,\n",
       "  3750,\n",
       "  338,\n",
       "  28421,\n",
       "  6382,\n",
       "  708,\n",
       "  263,\n",
       "  21114,\n",
       "  2752,\n",
       "  310,\n",
       "  848,\n",
       "  363,\n",
       "  24809,\n",
       "  292,\n",
       "  1766,\n",
       "  21998,\n",
       "  12469,\n",
       "  8773,\n",
       "  29903,\n",
       "  271,\n",
       "  20911,\n",
       "  6382,\n",
       "  708,\n",
       "  338,\n",
       "  263,\n",
       "  21114,\n",
       "  2752,\n",
       "  310,\n",
       "  848,\n",
       "  363,\n",
       "  24809,\n",
       "  292,\n",
       "  1766,\n",
       "  21998,\n",
       "  12469,\n",
       "  1363,\n",
       "  372,\n",
       "  6511,\n",
       "  2130,\n",
       "  304,\n",
       "  2472,\n",
       "  393,\n",
       "  338,\n",
       "  5189,\n",
       "  304,\n",
       "  4017,\n",
       "  491,\n",
       "  916,\n",
       "  2794,\n",
       "  29889,\n",
       "  12178,\n",
       "  514,\n",
       "  3246,\n",
       "  3867,\n",
       "  263,\n",
       "  5534,\n",
       "  1737,\n",
       "  12122,\n",
       "  23746,\n",
       "  322,\n",
       "  6314,\n",
       "  2472,\n",
       "  3785,\n",
       "  1711,\n",
       "  411,\n",
       "  1880,\n",
       "  25406,\n",
       "  10104,\n",
       "  29889,\n",
       "  910,\n",
       "  2794,\n",
       "  393,\n",
       "  28421,\n",
       "  4558,\n",
       "  508,\n",
       "  3867,\n",
       "  263,\n",
       "  15171,\n",
       "  6270,\n",
       "  1776,\n",
       "  310,\n",
       "  1766,\n",
       "  21998,\n",
       "  12469,\n",
       "  297,\n",
       "  263,\n",
       "  2183,\n",
       "  5120,\n",
       "  975,\n",
       "  931,\n",
       "  29889]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a7027c0-8b71-4afa-bde6-9dcca5d69d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 40\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=14)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0743ee6c-d84a-4dc3-bd75-b24e1b56f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      " Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 40\n",
      "})\n",
      "Testing Dataset:\n",
      " Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_ds = split_dataset[\"train\"]\n",
    "test_ds = split_dataset[\"test\"]\n",
    "print(\"Training Dataset:\\n\", train_ds)\n",
    "print(\"Testing Dataset:\\n\", test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca4b24-3f90-4780-a80c-82da6a71b348",
   "metadata": {},
   "source": [
    "## Training (Fine-tuning) using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f540923-810d-4d5a-8939-79d44741711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer class to include logging and history\n",
    "class Trainer(transformers.Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        model_flops,\n",
    "        total_steps,\n",
    "        args=None,\n",
    "        data_collator=None,\n",
    "        train_dataset=None,\n",
    "        eval_dataset=None,\n",
    "        tokenizer=None,\n",
    "        model_init=None,\n",
    "        compute_metrics=None,\n",
    "        callbacks=None,\n",
    "        optimizers=(None, None),\n",
    "    ):\n",
    "        super(Trainer, self).__init__(\n",
    "            model,\n",
    "            args,\n",
    "            data_collator,\n",
    "            train_dataset,\n",
    "            eval_dataset,\n",
    "            tokenizer,\n",
    "            model_init,\n",
    "            compute_metrics,\n",
    "            callbacks,\n",
    "            optimizers,\n",
    "        )\n",
    "\n",
    "        self.total_steps = total_steps\n",
    "        self.model_flops = model_flops\n",
    "        self.start_step = 0\n",
    "\n",
    "    def training_step(self, model, inputs):\n",
    "        if inputs[\"input_ids\"].numel() == 0:\n",
    "\n",
    "          print(\"Inputs: \", inputs)\n",
    "          print(\"Inputs - input_ids\", inputs[\"input_ids\"])\n",
    "          print(\"numel\", inputs[\"input_ids\"].numel())\n",
    "\n",
    "          return torch.tensor(0)\n",
    "        else:\n",
    "          model.train()\n",
    "          inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "          with self.compute_loss_context_manager():\n",
    "              loss = self.compute_loss(model, inputs)\n",
    "\n",
    "          if self.args.n_gpu > 1:\n",
    "              loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "\n",
    "          if self.do_grad_scaling:\n",
    "              self.scaler.scale(loss).backward()\n",
    "          else:\n",
    "              self.accelerator.backward(loss)\n",
    "\n",
    "          return loss.detach() / self.args.gradient_accumulation_steps\n",
    "\n",
    "    def log(self, logs):\n",
    "        \"\"\"\n",
    "        Log `logs` on the various objects watching training.\n",
    "        Subclass and override this method to inject custom behavior.\n",
    "        Args:\n",
    "            logs (`Dict[str, float]`):\n",
    "                The values to log.\n",
    "        \"\"\"\n",
    "        if self.state.epoch is not None:\n",
    "            logs[\"epoch\"] = round(self.state.epoch, 2)\n",
    "\n",
    "        self.update_log_timing(logs)\n",
    "\n",
    "        output = {**logs, **{\"step\": self.state.global_step}}\n",
    "        self.update_history(output)\n",
    "\n",
    "        logger.debug(\"Step (\" + str(self.state.global_step) + \") Logs: \" + str(logs))\n",
    "        self.control = self.callback_handler.on_log(\n",
    "            self.args, self.state, self.control, logs\n",
    "        )\n",
    "\n",
    "    def update_log_timing(self, logs):\n",
    "        if len(self.state.log_history) == 0:\n",
    "            self.start_time = time.time()\n",
    "            logs[\"iter_time\"] = 0.0\n",
    "            logs[\"flops\"] = 0.0\n",
    "            logs[\"remaining_time\"] = 0.0\n",
    "            self.start_step = self.state.global_step\n",
    "        elif self.state.global_step > self.start_step:\n",
    "            logs[\"iter_time\"] = (time.time() - self.start_time) / (\n",
    "                self.state.global_step - self.start_step\n",
    "            )\n",
    "            logs[\"flops\"] = self.model_flops / logs[\"iter_time\"]\n",
    "            logs[\"remaining_time\"] = (self.total_steps - self.state.global_step) * logs[\n",
    "                \"iter_time\"\n",
    "            ]\n",
    "\n",
    "    def update_history(self, output):\n",
    "        if \"eval_loss\" in output:\n",
    "            return\n",
    "        if len(self.state.log_history) > 0:\n",
    "            smoothing_window = 100\n",
    "            p = 1.0 / smoothing_window\n",
    "            if \"loss\" in output:\n",
    "                output[\"loss\"] = output[\"loss\"] * p + self.state.log_history[-1][\n",
    "                    \"loss\"\n",
    "                ] * (1.0 - p)\n",
    "        self.state.log_history.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e15c5f1-bb7d-4f2b-bad8-532f153ce64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96ca5b54-1189-4f3c-bc90-99d50cb5a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You shouldn't move a model when it is dispatched on multiple devices.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You can't move a model that has some modules offloaded to cpu or disk.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\accelerate\\big_modeling.py:410\u001b[0m, in \u001b[0;36mdispatch_model.<locals>.add_warning.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 410\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt move a model that has some modules offloaded to cpu or disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You can't move a model that has some modules offloaded to cpu or disk."
     ]
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81c79b3-815b-4770-aff5-75f5168c6fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What is the significance of ship detection with satellite imagery?\n",
      "Correct answer from Lamini docs: Ship detection with satellite imagery has various applications, such as maritime surveillance, vessel traffic management, illegal fishing detection, and monitoring trade activities.\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "Ship detection with satellite imagery has several significant applications, including:\n",
      "\n",
      "1. Maritime Security: Ship detection can help identify illegal activities such as drug trafficking, piracy, and smuggling.\n",
      "2. Environmental Monitoring: Ship detection can help track the movement of oil spills, pollutants, and other environmental hazards.\n",
      "3. Navigation and Saf\n"
     ]
    }
   ],
   "source": [
    "test_text = test_ds[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from Lamini docs: {test_ds[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference(test_text, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017bed8-9c97-4c39-b820-fb68303fa198",
   "metadata": {},
   "source": [
    "#### Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6638142d-7047-4b9b-8631-9cae5830fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ecb31478-ba86-4afa-aa10-e356eac1ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model_name = f\"{model_name}_{max_steps}_steps_{date.today()}--{datetime.now().strftime('%H;%M')}\"\n",
    "trained_model_name = f\"{model_name}_{max_steps}_steps_Satellite-{date.today()}--{datetime.now().strftime('%H;%M')}\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c091a98f-4d69-412c-94d4-2dffcd36b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=2.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=30,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a133d89a-df73-4f4b-9e35-6a7a15491571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 512)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
      ")\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 2195.667812352 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_flops = (\n",
    "  model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, max_length)\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(\"Memory footprint\", model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "56161875-5859-4e3d-9dac-ba84513c6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ea7f2eef-a0a4-43e0-8f12-c4ce1e91a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 06:26, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.013942</td>\n",
       "      <td>4.997031</td>\n",
       "      <td>352.875124</td>\n",
       "      <td>5475556488160.918945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.381349</td>\n",
       "      <td>5.724802</td>\n",
       "      <td>300.313096</td>\n",
       "      <td>5556559329888.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.174673</td>\n",
       "      <td>6.009246</td>\n",
       "      <td>252.835046</td>\n",
       "      <td>5557882182907.407227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.105261</td>\n",
       "      <td>6.208739</td>\n",
       "      <td>204.001213</td>\n",
       "      <td>5596767033568.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>6.297903</td>\n",
       "      <td>155.939001</td>\n",
       "      <td>5632119732029.251953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.071567</td>\n",
       "      <td>6.391783</td>\n",
       "      <td>108.683712</td>\n",
       "      <td>5656661681397.458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.066342</td>\n",
       "      <td>6.495336</td>\n",
       "      <td>61.972798</td>\n",
       "      <td>5668726659740.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>6.540971</td>\n",
       "      <td>15.458036</td>\n",
       "      <td>5681621531441.122070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "86d5b647-f1ad-4aea-9b13-7923eddfbcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: EleutherAI/pythia-70m_1000_steps_Satellite-2023-08-30--15;27/final\n"
     ]
    }
   ],
   "source": [
    "save_dir = f'{output_dir}/final'\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d082e27b-a977-4f8d-8099-0f9989cc59c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
    "finetuned_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d1463840-39a9-4a7b-b120-4af3bbe65e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What are some algorithms commonly used for sentiment segmentation of images?\n",
      "\n",
      "Answer from dataset (test):\n",
      " Some common algorithms used for sentiment segmentation of images include Mask R-CNN, DeepLab, and U-Net. These algorithms leverage deep learning and convolutional neural network techniques to analyze and classify different regions of an image based on their sentiment or emotional content.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model's answer:\n",
      " \n",
      "\n",
      "A:\n",
      "\n",
      "I think you should use a simple algorithm to get the best results.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The\n",
      "\n",
      "Finetuned model's answer: \n",
      "Various algorithms can be used, including convolutional neural networks (CNNs), support vector machines (SVMs), random forests, or ensemble models, depending on the specific requirements and characteristics of the applied task. These algorithms can be used in various contexts, including sentiment segmentation, sentiment detection, and classification tasks, depending on the specific requirements and characteristics of the task. Additionally, some algorithms can perform better in some contexts, such as object detection\n"
     ]
    }
   ],
   "source": [
    "test_instance = 3\n",
    "test_question = test_ds[test_instance]['question']\n",
    "test_answer = test_ds[test_instance]['answer']\n",
    "print(\"Question input (test):\", test_question)\n",
    "print(\"\\nAnswer from dataset (test):\\n\", test_answer)\n",
    "print(\"\\nBase model's answer:\\n\",inference(test_question, base_model, tokenizer))\n",
    "print(\"\\nFinetuned model's answer: \")\n",
    "print(inference(test_question, finetuned_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5df545-1003-4f87-a7f9-45b887045fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"How are machine learning models trained for ship detection?\"\"\"\n",
    "print(inference(train_ds[5]['question'], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51783d0-5445-4fc4-b2f8-20fbe0f6e32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc70c0c9-7a0e-425d-8e3a-0165b8bb6bbe",
   "metadata": {},
   "source": [
    "## Training (Fine-tuning) using Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600ad49-45fd-45bf-9b96-2be125563850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It may need case-wise considerations:\n",
    "if model_name == \"bert-base-uncased\":\n",
    "    model = TFBertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "else:\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead91fcc-8357-4bcf-a5cd-2f284f549558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(3e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13498db1-1729-427b-8fa4-8b2a929639d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359df9f3-beb0-4ff0-aca1-abe532ecedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfe00b-b642-457f-8171-87a154db1119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371827f-41cf-454a-9c48-04baa44aa5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
