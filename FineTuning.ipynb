{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee5321d-d279-4bc6-8285-57a5d4a58ef1",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201fb057-6645-4047-99a3-42756338b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TFBertLMHeadModel\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976a291a-ef2c-4fde-aafa-57b3b9bcaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gptq import GPTQConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60530a72-4070-4ed2-a5a7-6627d9a9fd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 SUPER'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test whether torch is working\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630eb89f-e4eb-4740-ac1a-ed60468431b0",
   "metadata": {},
   "source": [
    "\n",
    "#### If you want to download a model or a tokenizer from Huggingface Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c69536bf-3741-4516-b1a5-5ca35368de11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b45373ee124be4b969e1249794a49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logging into HuggingFace account\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "# my_token:  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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa4840-bca9-43b3-8ed6-a2b47ed3c7a7",
   "metadata": {},
   "source": [
    "## Model and Tokenizer declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeca32d8-7660-4922-9f88-8ef123c60448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"bert-base-uncased\"\n",
    "# model_name = \"EleutherAI/pythia-70m\"\n",
    "model_name = 'meta-llama/Llama-2-7b-chat-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04aa7483-0537-497f-893a-67845e65586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gptq_config = GPTQConfig(bits=4, dataset = \"c4\", tokenizer=tokenizer)\n",
    "# quantization = GPTQConfig(bits=4, dataset = dataset, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b0004e-0d84-44bb-8057-fb6aa38f96e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3576435438374359b0d18493aa6f8fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model = TFBertLMHeadModel.from_pretrained(model_name)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# base_model = AutoModelForCausalLM.from_pretrained(model_name)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:2903\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2894\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   2896\u001b[0m     (\n\u001b[0;32m   2897\u001b[0m         model,\n\u001b[0;32m   2898\u001b[0m         missing_keys,\n\u001b[0;32m   2899\u001b[0m         unexpected_keys,\n\u001b[0;32m   2900\u001b[0m         mismatched_keys,\n\u001b[0;32m   2901\u001b[0m         offload_index,\n\u001b[0;32m   2902\u001b[0m         error_msgs,\n\u001b[1;32m-> 2903\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2921\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   2922\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mD:\\NLP 1\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3282\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3280\u001b[0m     \u001b[38;5;66;03m# force memory release\u001b[39;00m\n\u001b[0;32m   3281\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n\u001b[1;32m-> 3282\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m   3284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offload_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(offload_index) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m model_to_load:\n\u001b[0;32m   3286\u001b[0m         \u001b[38;5;66;03m# We need to add the prefix of the base model\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = TFBertLMHeadModel.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb94bb0-70ee-44dc-bfc1-74f826973c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c73bf69-160f-49d3-b1f9-192a2d45a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token    # for Eleuther model use this\n",
    "# tokenizer.pad_token = tokenizer.cls_token    # for Bert model use this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b6393-34e0-48fe-b75d-5f073650d8d0",
   "metadata": {},
   "source": [
    "## Preparing the dataset for Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397490d-7d4d-42a5-a82c-6cd72e614405",
   "metadata": {},
   "source": [
    "Provide a Json Lines (Jsonl) file containing question and answer pairs; like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b931e06-93db-4b56-ba16-2c7856d2fd72",
   "metadata": {},
   "source": [
    "{\"question\": \"what could be a use case of LLM for a hospital\", \"answer\": \"LLMs can have several applications in a hospital such as Assisstant for nurses\"}\n",
    "\n",
    "{\"question\": \"How AI is being used in medical industries?\", \"answer\":\" AI is being used in medical industries for various purposes such as disease diagnose\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fd5967a-d5e8-4f06-b69c-85ef6d30a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = \"ds.jsonl\"\n",
    "dataset_path = \"ds-sat.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a9d54fa-8ad0-4f34-a322-ae4341354eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_df = pd.read_json(\"ds.jsonl\", lines=True)\n",
    "# dict_dataset = df.to_dict()\n",
    "# print(\"dataset contains \" + str(len(dict_dataset['question'])) + \" Q & A\")\n",
    "# dict_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34ea013b-5432-4d82-a946-5d8e7741e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding and truncating mey be used if model input exceeds max_length\n",
    "max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f2f1e52-849b-4c30-9ac4-5cf2f9b07f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(dict_dataset):\n",
    "    if \"question\" in dict_dataset and \"answer\" in dict_dataset:\n",
    "      text = dict_dataset[\"question\"][0] + dict_dataset[\"answer\"][0]\n",
    "    elif \"input\" in dict_dataset and \"output\" in dict_dataset:\n",
    "      text = dict_dataset[\"input\"][0] + dict_dataset[\"output\"][0]\n",
    "    else:\n",
    "      text = dict_dataset[\"text\"][0]\n",
    "\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        padding=True,\n",
    "    )\n",
    "\n",
    "    max_length = min(\n",
    "        tokenized_inputs[\"input_ids\"].shape[1],\n",
    "        2048\n",
    "    )\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d95024f-6c1b-4001-b663-65b15df691f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=dataset_path, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf2fb1-0669-414e-97d7-d4daaa48ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = finetuning_dataset_loaded.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=1,\n",
    "    drop_last_batch=True\n",
    ")\n",
    "\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6950b1-f8dc-436a-b601-12867dbfb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d55b67-4eaf-4872-87d2-b155150b235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a7027c0-8b71-4afa-bde6-9dcca5d69d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 40\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=14)\n",
    "print(split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0743ee6c-d84a-4dc3-bd75-b24e1b56f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      " Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 40\n",
      "})\n",
      "Testing Dataset:\n",
      " Dataset({\n",
      "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 5\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_ds = split_dataset[\"train\"]\n",
    "test_ds = split_dataset[\"test\"]\n",
    "print(\"Training Dataset:\\n\", train_ds)\n",
    "print(\"Testing Dataset:\\n\", test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca4b24-3f90-4780-a80c-82da6a71b348",
   "metadata": {},
   "source": [
    "### PyTorch Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f540923-810d-4d5a-8939-79d44741711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer class to include logging and history\n",
    "class Trainer(transformers.Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        model_flops,\n",
    "        total_steps,\n",
    "        args=None,\n",
    "        data_collator=None,\n",
    "        train_dataset=None,\n",
    "        eval_dataset=None,\n",
    "        tokenizer=None,\n",
    "        model_init=None,\n",
    "        compute_metrics=None,\n",
    "        callbacks=None,\n",
    "        optimizers=(None, None),\n",
    "    ):\n",
    "        super(Trainer, self).__init__(\n",
    "            model,\n",
    "            args,\n",
    "            data_collator,\n",
    "            train_dataset,\n",
    "            eval_dataset,\n",
    "            tokenizer,\n",
    "            model_init,\n",
    "            compute_metrics,\n",
    "            callbacks,\n",
    "            optimizers,\n",
    "        )\n",
    "\n",
    "        self.total_steps = total_steps\n",
    "        self.model_flops = model_flops\n",
    "        self.start_step = 0\n",
    "\n",
    "    def training_step(self, model, inputs):\n",
    "        if inputs[\"input_ids\"].numel() == 0:\n",
    "\n",
    "          print(\"Inputs: \", inputs)\n",
    "          print(\"Inputs - input_ids\", inputs[\"input_ids\"])\n",
    "          print(\"numel\", inputs[\"input_ids\"].numel())\n",
    "\n",
    "          return torch.tensor(0)\n",
    "        else:\n",
    "          model.train()\n",
    "          inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "          with self.compute_loss_context_manager():\n",
    "              loss = self.compute_loss(model, inputs)\n",
    "\n",
    "          if self.args.n_gpu > 1:\n",
    "              loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "\n",
    "          if self.do_grad_scaling:\n",
    "              self.scaler.scale(loss).backward()\n",
    "          else:\n",
    "              self.accelerator.backward(loss)\n",
    "\n",
    "          return loss.detach() / self.args.gradient_accumulation_steps\n",
    "\n",
    "    def log(self, logs):\n",
    "        \"\"\"\n",
    "        Log `logs` on the various objects watching training.\n",
    "        Subclass and override this method to inject custom behavior.\n",
    "        Args:\n",
    "            logs (`Dict[str, float]`):\n",
    "                The values to log.\n",
    "        \"\"\"\n",
    "        if self.state.epoch is not None:\n",
    "            logs[\"epoch\"] = round(self.state.epoch, 2)\n",
    "\n",
    "        self.update_log_timing(logs)\n",
    "\n",
    "        output = {**logs, **{\"step\": self.state.global_step}}\n",
    "        self.update_history(output)\n",
    "\n",
    "        logger.debug(\"Step (\" + str(self.state.global_step) + \") Logs: \" + str(logs))\n",
    "        self.control = self.callback_handler.on_log(\n",
    "            self.args, self.state, self.control, logs\n",
    "        )\n",
    "\n",
    "    def update_log_timing(self, logs):\n",
    "        if len(self.state.log_history) == 0:\n",
    "            self.start_time = time.time()\n",
    "            logs[\"iter_time\"] = 0.0\n",
    "            logs[\"flops\"] = 0.0\n",
    "            logs[\"remaining_time\"] = 0.0\n",
    "            self.start_step = self.state.global_step\n",
    "        elif self.state.global_step > self.start_step:\n",
    "            logs[\"iter_time\"] = (time.time() - self.start_time) / (\n",
    "                self.state.global_step - self.start_step\n",
    "            )\n",
    "            logs[\"flops\"] = self.model_flops / logs[\"iter_time\"]\n",
    "            logs[\"remaining_time\"] = (self.total_steps - self.state.global_step) * logs[\n",
    "                \"iter_time\"\n",
    "            ]\n",
    "\n",
    "    def update_history(self, output):\n",
    "        if \"eval_loss\" in output:\n",
    "            return\n",
    "        if len(self.state.log_history) > 0:\n",
    "            smoothing_window = 100\n",
    "            p = 1.0 / smoothing_window\n",
    "            if \"loss\" in output:\n",
    "                output[\"loss\"] = output[\"loss\"] * p + self.state.log_history[-1][\n",
    "                    \"loss\"\n",
    "                ] * (1.0 - p)\n",
    "        self.state.log_history.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e15c5f1-bb7d-4f2b-bad8-532f153ce64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenize\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",\n",
    "          truncation=True,\n",
    "          max_length=max_input_tokens\n",
    "  )\n",
    "\n",
    "  # Generate\n",
    "  device = model.device\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),\n",
    "    max_length=max_output_tokens\n",
    "  )\n",
    "\n",
    "  # Decode\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the prompt\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "96ca5b54-1189-4f3c-bc90-99d50cb5a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d81c79b3-815b-4770-aff5-75f5168c6fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What is the significance of ship detection with satellite imagery?\n",
      "Correct answer from Lamini docs: Ship detection with satellite imagery has various applications, such as maritime surveillance, vessel traffic management, illegal fishing detection, and monitoring trade activities.\n",
      "Model's answer: \n",
      "\n",
      "\n",
      "The answer is that the satellite imagery is not a satellite imagery, but a satellite imagery. The satellite imagery is a satellite imagery of the moon, the moon, the moon, and the moon. The satellite imagery is a satellite imagery of the moon, the moon, and the moon. The satellite imagery is a satellite imagery of the moon, the moon, and the moon. The satellite imagery is a satellite imagery of the moon, the\n"
     ]
    }
   ],
   "source": [
    "test_text = test_ds[0]['question']\n",
    "print(\"Question input (test):\", test_text)\n",
    "print(f\"Correct answer from Lamini docs: {test_ds[0]['answer']}\")\n",
    "print(\"Model's answer: \")\n",
    "print(inference(test_text, model, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c017bed8-9c97-4c39-b820-fb68303fa198",
   "metadata": {},
   "source": [
    "#### Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6638142d-7047-4b9b-8631-9cae5830fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ecb31478-ba86-4afa-aa10-e356eac1ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model_name = f\"{model_name}_{max_steps}_steps_{date.today()}--{datetime.now().strftime('%H;%M')}\"\n",
    "trained_model_name = f\"{model_name}_{max_steps}_steps_Satellite-{date.today()}--{datetime.now().strftime('%H;%M')}\"\n",
    "output_dir = trained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c091a98f-4d69-412c-94d4-2dffcd36b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "\n",
    "  # Learning rate\n",
    "  learning_rate=2.0e-5,\n",
    "\n",
    "  # Number of training epochs\n",
    "  num_train_epochs=30,\n",
    "\n",
    "  # Max steps to train for (each step is a batch of data)\n",
    "  # Overrides num_train_epochs, if not -1\n",
    "  max_steps=max_steps,\n",
    "\n",
    "  # Batch size for training\n",
    "  per_device_train_batch_size=1,\n",
    "\n",
    "  # Directory to save model checkpoints\n",
    "  output_dir=output_dir,\n",
    "\n",
    "  # Other arguments\n",
    "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
    "  disable_tqdm=False, # Disable progress bars\n",
    "  eval_steps=120, # Number of update steps between two evaluations\n",
    "  save_steps=120, # After # steps model is saved\n",
    "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
    "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "  evaluation_strategy=\"steps\",\n",
    "  logging_strategy=\"steps\",\n",
    "  logging_steps=1,\n",
    "  optim=\"adafactor\",\n",
    "  gradient_accumulation_steps = 4,\n",
    "  gradient_checkpointing=False,\n",
    "\n",
    "  # Parameters for early stopping\n",
    "  load_best_model_at_end=True,\n",
    "  save_total_limit=1,\n",
    "  metric_for_best_model=\"eval_loss\",\n",
    "  greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a133d89a-df73-4f4b-9e35-6a7a15491571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 512)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
      ")\n",
      "Memory footprint 0.30687256 GB\n",
      "Flops 2195.667812352 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model_flops = (\n",
    "  model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, max_length)\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_args.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(\"Memory footprint\", model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "56161875-5859-4e3d-9dac-ba84513c6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    model_flops=model_flops,\n",
    "    total_steps=max_steps,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ea7f2eef-a0a4-43e0-8f12-c4ce1e91a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 06:26, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.013942</td>\n",
       "      <td>4.997031</td>\n",
       "      <td>352.875124</td>\n",
       "      <td>5475556488160.918945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.381349</td>\n",
       "      <td>5.724802</td>\n",
       "      <td>300.313096</td>\n",
       "      <td>5556559329888.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.174673</td>\n",
       "      <td>6.009246</td>\n",
       "      <td>252.835046</td>\n",
       "      <td>5557882182907.407227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.105261</td>\n",
       "      <td>6.208739</td>\n",
       "      <td>204.001213</td>\n",
       "      <td>5596767033568.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>6.297903</td>\n",
       "      <td>155.939001</td>\n",
       "      <td>5632119732029.251953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.071567</td>\n",
       "      <td>6.391783</td>\n",
       "      <td>108.683712</td>\n",
       "      <td>5656661681397.458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.066342</td>\n",
       "      <td>6.495336</td>\n",
       "      <td>61.972798</td>\n",
       "      <td>5668726659740.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>6.540971</td>\n",
       "      <td>15.458036</td>\n",
       "      <td>5681621531441.122070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "86d5b647-f1ad-4aea-9b13-7923eddfbcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: EleutherAI/pythia-70m_1000_steps_Satellite-2023-08-30--15;27/final\n"
     ]
    }
   ],
   "source": [
    "save_dir = f'{output_dir}/final'\n",
    "\n",
    "trainer.save_model(save_dir)\n",
    "print(\"Saved model to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d082e27b-a977-4f8d-8099-0f9989cc59c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n",
    "finetuned_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d1463840-39a9-4a7b-b120-4af3bbe65e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question input (test): What are some algorithms commonly used for sentiment segmentation of images?\n",
      "\n",
      "Answer from dataset (test):\n",
      " Some common algorithms used for sentiment segmentation of images include Mask R-CNN, DeepLab, and U-Net. These algorithms leverage deep learning and convolutional neural network techniques to analyze and classify different regions of an image based on their sentiment or emotional content.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model's answer:\n",
      " \n",
      "\n",
      "A:\n",
      "\n",
      "I think you should use a simple algorithm to get the best results.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The algorithm is called the \"best\" algorithm.\n",
      "The\n",
      "\n",
      "Finetuned model's answer: \n",
      "Various algorithms can be used, including convolutional neural networks (CNNs), support vector machines (SVMs), random forests, or ensemble models, depending on the specific requirements and characteristics of the applied task. These algorithms can be used in various contexts, including sentiment segmentation, sentiment detection, and classification tasks, depending on the specific requirements and characteristics of the task. Additionally, some algorithms can perform better in some contexts, such as object detection\n"
     ]
    }
   ],
   "source": [
    "test_instance = 3\n",
    "test_question = test_ds[test_instance]['question']\n",
    "test_answer = test_ds[test_instance]['answer']\n",
    "print(\"Question input (test):\", test_question)\n",
    "print(\"\\nAnswer from dataset (test):\\n\", test_answer)\n",
    "print(\"\\nBase model's answer:\\n\",inference(test_question, base_model, tokenizer))\n",
    "print(\"\\nFinetuned model's answer: \")\n",
    "print(inference(test_question, finetuned_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5df545-1003-4f87-a7f9-45b887045fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"How are machine learning models trained for ship detection?\"\"\"\n",
    "print(inference(train_ds[5]['question'], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51783d0-5445-4fc4-b2f8-20fbe0f6e32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc70c0c9-7a0e-425d-8e3a-0165b8bb6bbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tensorflow Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600ad49-45fd-45bf-9b96-2be125563850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It may need case-wise considerations:\n",
    "if model_name == \"bert-base-uncased\":\n",
    "    model = TFBertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "else:\n",
    "    model = TFAutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead91fcc-8357-4bcf-a5cd-2f284f549558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(3e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13498db1-1729-427b-8fa4-8b2a929639d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359df9f3-beb0-4ff0-aca1-abe532ecedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfe00b-b642-457f-8171-87a154db1119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371827f-41cf-454a-9c48-04baa44aa5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
